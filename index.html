<!DOCTYPE html> <html lang="en"> <head> <meta name="google-site-verification" content="google-site-verification=-tQTiBN1KJC5IEnwwvXfdPCoMmFnyFKcHeRsi2gp3Io"/> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Siddhartha Mishra</title> <meta name="author" content="Siddhartha Mishra"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>📑</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://sidmishra.com/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <div class="toggle-container"> <a id="light-toggle"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </a> </div> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Siddhartha</span> Mishra </h1> <p class="desc">ML Researcher at Palantir</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img class="img-fluid z-dept-1 rounded" src="/assets/img/prof_pic.jpg" alt="prof_pic.jpg"> </picture> </figure> </div> <div class="clearfix"> <p>I’m a Machine Learning Researcher at <a href="https://www.palantir.com/" target="_blank" rel="noopener noreferrer">Palantir</a> working on improving agentic and retrieval-augmented workflows with Large Language Models (LLMs). My research interests are in the intersection of Natural Language Processing and Machine Learning. Recently, I have been interested in evaluation frameworks, structured prediction, and efficiency in LLMs.</p> <p>Previously, I was an Applied scientist intern at <a href="https://www.amazon.science/tag/alexa" target="_blank" rel="noopener noreferrer">Amazon Alexa AI - NLU</a> and an Analyst at <a href="https://www.goldmansachs.com/" target="_blank" rel="noopener noreferrer">Goldman Sachs</a>. I was supervised by <a href="https://people.cs.umass.edu/~mccallum/" target="_blank" rel="noopener noreferrer">Prof. Andrew McCallum</a> during my grad school at <a href="https://nlp.cs.umass.edu/" target="_blank" rel="noopener noreferrer">UMass NLP</a>. I also did my Bachelor’s in Computer Science at <a href="https://iith.ac.in/" target="_blank" rel="noopener noreferrer">Indian Institute of Technology, Hyderabad</a>, where I worked on Bayesian Machine Learning and Natural Language Processing with <a href="https://sites.google.com/site/pksrijith/home" target="_blank" rel="noopener noreferrer">Prof. Srijith P.K.</a>.</p> </div> <div class="news"> <h2>News</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Jan 13, 2023</th> <td> Started a new position as a founding member of the <a href="https://www.palantir.com/offerings/ai-ml/" target="_blank" rel="noopener noreferrer"> Palantir NLP research </a> team </td> </tr> <tr> <th scope="row">Jun 2, 2022</th> <td> Started an Applied Scientist Internship at <a href="https://www.amazon.science/tag/nlu" target="_blank" rel="noopener noreferrer"> Amazon Alexa AI NLU </a> </td> </tr> <tr> <th scope="row">Feb 25, 2022</th> <td> Presented a poster at <a href="https://aaai-2022.virtualchair.net/poster_aaai11084" target="_blank" rel="noopener noreferrer"> AAAI 2022 </a> </td> </tr> </table> </div> </div> <div class="publications"> <h2>Selected Publications</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">EMNLP</abbr></div> <div id="https://doi.org/10.48550/arxiv.2204.07705" class="col-sm-8"> <div class="title">Benchmarking Generalization via In-Context Instructions on 1,600+ Language Tasks</div> <div class="author">Wang, Yizhong, Mishra, Swaroop, Alipoormolabashi, Pegah,  <em>Mishra, Siddhartha</em>, and others, </div> <div class="periodical"> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2204.07705" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://github.com/allenai/natural-instructions" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>How can we measure the generalization of models to a variety of unseen tasks when provided with their language instructions? To facilitate progress in this goal, we introduce Natural-Instructions v2, a benchmark of 1,600+ diverse language tasks and their expert-written instructions. It covers 70+ distinct task types, such as tagging, in-filling, and rewriting. These tasks are collected with contributions of NLP practitioners in the community and through an iterative peer review process to ensure their quality. With this large and diverse collection of tasks, we are able to rigorously benchmark cross-task generalization of models – training on a subset of tasks and evaluating on the remaining unseen ones. For instance, we quantify generalization as a function of various scaling parameters, such as the number of observed tasks, the number of instances, and model sizes. Based on these insights, we introduce Tk-Instruct, an encoder-decoder Transformer that is trained to follow a variety of in-context instructions (plain language task definitions or k-shot examples) which outperforms existing larger models on our benchmark. We hope this benchmark facilitates future progress toward more general-purpose language understanding models.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ACL</abbr></div> <div id="dasgupta-etal-2022-word2box" class="col-sm-8"> <div class="title">Word2Box: Capturing Set-Theoretic Semantics of Words using Box Embeddings</div> <div class="author">Dasgupta, Shib, Boratko, Michael,  <em>Mishra, Siddhartha</em>, Atmakuri, Shriya, Patel, Dhruvesh, Li, Xiang, and McCallum, Andrew </div> <div class="periodical"> <em>In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aclanthology.org/2022.acl-long.161" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>Learning representations of words in a continuous space is perhaps the most fundamental task in NLP, however words interact in ways much richer than vector dot product similarity can provide. Many relationships between words can be expressed set-theoretically, for example, adjective-noun compounds (eg. “red cars”⊆“cars”) and homographs (eg. “tongue”∩“body” should be similar to “mouth”, while “tongue”∩“language” should be similar to “dialect”) have natural set-theoretic interpretations. Box embeddings are a novel region-based representation which provide the capability to perform these set-theoretic operations. In this work, we provide a fuzzy-set interpretation of box embeddings, and learn box representations of words using a set-theoretic training objective. We demonstrate improved performance on various word similarity tasks, particularly on less common words, and perform a quantitative and qualitative analysis exploring the additional unique expressivity provided by Word2Box.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">AAAI</abbr></div> <div id="mishra2022clusthypeval" class="col-sm-8"> <div class="title">An Evaluative Measure of Clustering Methods Incorporating Hyperparameter Sensitivity</div> <div class="author"> <em>Mishra, Siddhartha</em>, Monath, Nicholas, Boratko, Michael, Kobren, Ari, and McCallum, Andrew </div> <div class="periodical"> <em>In Proceedings of the AAAI Conference on Artificial Intelligence</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://aaai-2022.virtualchair.net/poster_aaai11084" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://github.com/mishra-sid/clustering_hyperparameters" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>Abstract: Clustering algorithms are often evaluated using metrics which compare with ground-truth cluster assignments, such as Rand index and NMI. Algorithm performance may vary widely for different hyperparameters, however, and thus model selection based on optimal performance for these metrics is discordant with how these algorithms are applied in practice, where labels are unavailable and tuning is often more art than science. It is therefore desirable to compare clustering algorithms not only on their optimally tuned performance, but also some notion of how realistic it would be to obtain this performance in practice. We propose an evaluation of clustering methods capturing this ease-of-tuning by modeling the expected best clustering score under a given computation budget. To encourage the adoption of the proposed metric alongside classic clustering evaluations, we provide an extensible benchmarking framework. We perform an extensive empirical evaluation of our proposed metric on popular clustering algorithms over a large collection of datasets from different domains, and observe that our new metric leads to several noteworthy observations.</p> </div> </div> </div> </li> </ol> </div> <div class="service"> <h2>Service</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Reviewer</th> <td> <p>NAACL 2025, ICLR 2025, NeurIPS 2024, EMNLP 2024, ACL 2023, AAAI 2023, EMNLP 2022</p> </td> </tr> <tr> <th scope="row">Teaching Assistant</th> <td> <p>Machine Learning (Fall 2021), Statistics (Spring 2019), Computer Networks (Fall 2018), Probability (Fall 2017).</p> </td> </tr> </table> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%69%6D.%73%69%64%64%68%61%72%74%68%61.%6D%69%73%68%72%61@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=NpUFy1kAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/mishra-sid" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/sidmishra97" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a> <a href="https://twitter.com/mishra_sid97" title="Twitter" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i></a> <a href="https://sidmishra.com/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a> </div> <div class="contact-note"> The best way to reach out to me is by email: im.siddhartha.mishra at gmail.com </div> </div> </div> </article> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2024 Siddhartha Mishra. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script src="/assets/js/zoom.js"></script> <script src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </div></body> </html>